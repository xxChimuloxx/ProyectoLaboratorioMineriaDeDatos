# README ‚Äî Proyecto Telco Churn Pipeline (MLOps)
## Proyecto Laboratorio Mineria de Datos
### Nombre del Proyecto: Telco Churn 
### Tipo: Pipeline Reproducible con MLOps, DVC y GitHub Actions

## Introduccion
Este repositorio contiene el desarrollo completo de un pipeline reproducible de Machine Learning orientado a la predicci√≥n de churn (baja de clientes) para la empresa ficticia TelcoVision. El proyecto replica el flujo de trabajo de un equipo real de datos, aplicando buenas pr√°cticas de MLOps, versionado de datos y modelos, experimentaci√≥n con trazabilidad, CI/CD y documentaci√≥n profesional.

El objetivo principal fue construir un sistema capaz de predecir si un cliente abandonar√° el servicio (churn = 1) o permanecer√° activo (churn = 0), utilizando datos demogr√°ficos, de uso y de facturaci√≥n.

## üóÇÔ∏è Estructura del Repositorio

``` python
Proyecto/
‚îú‚îÄ‚îÄ data/
‚îÇ   
‚îú‚îÄ‚îÄ raw/                  # Dataset original (versionado por DVC)
‚îÇ   
‚îî‚îÄ‚îÄ processed/            # Dataset limpio generado por el pipeline
‚îú‚îÄ‚îÄ models/                   # Modelos entrenados (bajo control DVC)
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îî‚îÄ‚îÄ roc_curve.png         # Curva ROC del modelo final
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_prep.py          # Script de limpieza y preparaci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ train.py              # Entrenamiento del modelo (Logistic Regression)
‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py           # Evaluaci√≥n extendida + curva ROC
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ ci.yaml               # Workflow de CI/CD con GitHub Actions
‚îú‚îÄ‚îÄ params.yaml               # Hiperpar√°metros del modelo
‚îú‚îÄ‚îÄ dvc.yaml                  # Definici√≥n del pipeline completo
‚îú‚îÄ‚îÄ dvc.lock                  # Registro determin√≠stico de versiones
‚îú‚îÄ‚îÄ metrics.json              # M√©tricas base del modelo
‚îú‚îÄ‚îÄ metrics_extended.json     # M√©tricas extendidas
‚îî‚îÄ‚îÄ README.md                 # (este archivo)
``` 

## üóÇÔ∏è Dataset

Archivo original: 
> data/raw/telco_churn.xlsx

Caracter√≠sticas principales:

- 10.000 registros
- Variables demogr√°ficas
- Servicios contratados
- M√©todos de pago
- Cargos mensuales y acumulados
- Variable objetivo: 
> churn

El dataset est√° versionado con DVC y almacenado en DagsHub.

## ‚öôÔ∏è Pipeline Reproducible (DVC)

El pipeline se compone de 3 stages:

> data_prep

- Limpieza de datos:
- elimina duplicados
- corrige valores faltantes
- genera data/processed/telco_clean.csv

> train

- Entrenamiento del modelo:
- modelo base: Logistic Regression
- hiperpar√°metros controlados por params.yaml
- guarda modelo en models/model.pkl
- genera m√©tricas en metrics.json

> evaluate

- Evaluaci√≥n adicional del modelo:
- m√©tricas extendidas (precision, recall, f1, roc_auc)
- curva ROC en reports/roc_curve.png
- archivo metrics_extended.json

Ejecuci√≥n completa del pipeline:
``` python
dvc repro
``` 

Reproducible en cualquier m√°quina con:
``` python
dvc pull
dvc repro
``` 

## üîç Experimentos (DVC Experiments)

Se realizaron m√∫ltiples experimentos variando hiperpar√°metros con:
``` python
dvc exp run --set-param train.C=0.5
dvc exp run --set-param train.C=2.0 --set-param train.max_iter=300
``` 

Comparaci√≥n de experimentos:
``` python
dvc exp show
``` 

Se seleccion√≥ como modelo final el experimento con:

- C = 0.5
- F1 superior al baseline
- Mejor estabilidad en validaci√≥n

Aplicaci√≥n del mejor experimento:
``` python
dvc exp apply <ID>
``` 

## üîÅ Integraci√≥n Continua (CI/CD)

Se implement√≥ un workflow en GitHub Actions:
> .github/workflows/ci.yaml

El CI ejecuta:

1. nstalaci√≥n de dependencias
2. Configuraci√≥n de DVC remote
3. dvc pull
4. dvc repro
5. Publicaci√≥n de m√©tricas

Los secretos usados:

- DAGSHUB_USER
- DAGSHUB_TOKEN

CI corre en:

- ada push a main
- cada Pull Request

Un PR v√°lido muestra:

- ‚úîÔ∏è Checks en verde
- ‚úîÔ∏è Pipeline ejecutado
- ‚úîÔ∏è M√©tricas impresas

Esto asegura que cualquier cambio rompe o valida el pipeline autom√°ticamente.

## Iteraci√≥n Colaborativa (Etapa 6)

En esta seccion se replic√≥ el flujo de trabajo de un equipo profesional:

- ramas feat-*
- Pull Requests
- validaci√≥n autom√°tica con CI
- merge del mejor experimento

Se generaron capturas de evidencia mostrando:

- PR creado
- CI ejecut√°ndose y aprobado
- cambios integrados en main

Toda la historia est√° disponible en el historial del repositorio.

## Evaluaci√≥n Extendida (Etapa 7)

Se implement√≥ evaluate.py, que genera:

- precisi√≥n
- recall
- f1-score
- roc_auc
- curva ROC

La curva ROC final est√° almacenada en reports/roc_curve.png.

## Despliegue del Modelo (Dise√±o Conceptual)
Aunque no se exigi√≥ un servicio real, se document√≥ c√≥mo desplegarlo:

‚úîÔ∏è Opci√≥n A ‚Äî API con FastAPI

- Un servidor FastAPI podr√≠a:
- cargar models/model.pkl
- recibir datos de cliente en JSON
- aplicar preprocesamiento
- retornar probabilidad de churn

Endpoint sugerido:
``` python
POST /predict
``` 

‚úîÔ∏è Opci√≥n B ‚Äî Dashboard en Streamlit

Ideal para usuarios de negocio:

- sliders para edad, tipo de contrato, cargo mensual, etc.
- predicci√≥n en tiempo real
- explicaci√≥n del resultado

‚úîÔ∏è Beneficios del enfoque MLOps:

- reproducibilidad garantizada (DVC + GitHub Actions)
- trazabilidad de datos y modelos
- integraci√≥n segura mediante versi√≥n de artefactos

üé• Video de Presentaci√≥n (pendiente para entrega final)

El video de 10‚Äì15 minutos debe mostrar:

- caso de uso
- pipeline completo
- ejecuci√≥n real (git clone, dvc pull, dvc repro)
- experimentos
- CI en PR
- conclusiones

El enlace ser√° incluido en este README cuando est√© listo.

## üë§ Autores

- xxxx
- xxxx
- xxxx

Proyecto acad√©mico ‚Äî ISTEA
MLOps / Data Mining Laboratory
2025

## Instrucciones para reproducir el proyecto

Clonar repo:
``` python
git clone https://github.com/xxChimuloxx/ProyectoLaboratorioMineriaDeDatos
``` 

Entrar al directorio:
``` python
cd ProyectoLaboratorioMineriaDeDatos
``` 

Instalar dependencias:
``` python
pip install -r requirements.txt
``` 

Obtener los datos:
``` python
dvc pull
``` 

Reproducir pipeline:
``` python
dvc repro
```

## üì¶ Estado del Proyecto

- ‚úÖ Setup inicial (Completo)
- ‚úÖ Limpieza + features (Completo)
- ‚úÖ Entrenamiento (Completo)
- ‚úÖ Experimentos (Completo)
- ‚úÖ CI/CD (Completo)
- ‚úÖ Iteraci√≥n colaborativa (Completo)
- ‚úÖ Evaluaci√≥n extendida (bonus) (Completo)


#
# ADICIONALES

## Comparaci√≥n Exhaustiva de los Experimentos

La fase de experimentaci√≥n se desarroll√≥ utilizando **DVC Experiments**, lo que permiti√≥ registrar sistem√°ticamente cada combinaci√≥n de hiperpar√°metros, sus m√©tricas resultantes y los artefactos asociados (modelo, m√©tricas y versions del lock file). Este enfoque garantiza trazabilidad total: cada experimento puede ser recreado, comparado, revertido o aplicado al workspace en cualquier momento.

El modelo inicial consisti√≥ en una **Logistic Regression** con par√°metros por defecto. A partir de esta base, se ejecutaron m√∫ltiples experimentos con variaciones espec√≠ficas en los par√°metros de regularizaci√≥n y n√∫mero m√°ximo de iteraciones.

### Contexto estad√≠stico del problema
El dataset de churn presenta caracter√≠sticas t√≠picas del dominio:
- Ligero desbalance entre clases (la cantidad de clientes que se dan de baja es menor que los que permanecen activos).
- Variables categ√≥ricas de alta cardinalidad (regi√≥n, tipo de contrato, m√©todo de pago).
- Efectos no lineales que una regresi√≥n log√≠stica simple puede no capturar completamente.
En este tipo de contextos, la m√©trica F1 suele ser m√°s informativa que la accuracy, ya que penaliza m√°s los falsos negativos (clientes que abandonan y no se predicen como tal).

---

### **üîπ Baseline**
Modelo inicial sin cambios de hiperpar√°metros:
- **Accuracy:** 0.6855  
- **F1-score:** 0.5158  
- Sin advertencias relevantes.

Este baseline sirve como punto de referencia para evaluar si vale la pena aumentar (o disminuir) la fuerza de regularizaci√≥n.

---

### **üîπ Experimento 1 ‚Äî Regularizaci√≥n m√°s fuerte (`C = 0.5`)**

- **Accuracy:** 0.6885  
- **F1-score:** 0.5197  
- Sin warnings de convergencia.

**Interpretaci√≥n:**  
Reducir el valor de C en una regresi√≥n log√≠stica implica **aumentar la penalizaci√≥n L2**, promoviendo coeficientes m√°s peque√±os y un modelo menos sensible al ruido.  
Este experimento produjo una mejora simult√°nea en accuracy y F1-score, indicando:
- mejor capacidad de generalizaci√≥n,  
- menor sobreajuste,  
- mayor sensibilidad a la clase minoritaria.  

Esto es especialmente significativo en churn: detectar correctamente al cliente que se va es m√°s importante que predecir correctamente al cliente que se queda.

---

### **üîπ Experimento 2 ‚Äî Regularizaci√≥n m√°s d√©bil (`C = 2.0`) y mayor `max_iter`**

- **Accuracy:** 0.6845  
- **F1-score:** 0.5135  
- **Advertencias de convergencia**, incluso con 300 iteraciones.

**Interpretaci√≥n:**  
Un valor alto de C reduce la regularizaci√≥n y permite que el modelo sea m√°s flexible. Sin embargo:
- No mejor√≥ los resultados,
- Mostr√≥ mayor sensibilidad al ruido,
- Exigi√≥ m√°s iteraciones sin resolver el problema de convergencia.

Esto indica que el modelo estaba intentando ajustar patrones que no aportaban al desempe√±o real, t√≠pico s√≠ntoma de **sobreajuste**.

---

### **Comparativa Final**

| Experimento | C | max_iter | Accuracy | F1-score | Estabilidad |
|------------|---|----------|----------|----------|-------------|
| Baseline   | 1.0 | 200 | 0.6855 | 0.5158 | Estable |
| Exp. 1     | 0.5 | 200 | **0.6885** | **0.5197** | Muy estable |
| Exp. 2     | 2.0 | 300 | 0.6845 | 0.5135 | Con warnings |

**Conclusi√≥n general:**  
‚û°Ô∏è El experimento con `C = 0.5` ofrece el **mejor equilibrio entre estabilidad, generalizaci√≥n y m√©tricas cr√≠ticas para el dominio de churn**.

---

## Justificaci√≥n en detalle del Modelo Final Elegido

El modelo final seleccionado corresponde al experimento con **regularizaci√≥n moderada (`C = 0.5`)**, debido a una combinaci√≥n de factores t√©cnicos y pr√°cticos relevantes para su futuro despliegue.

### **1. Superioridad en m√©tricas prioritarias**
Aunque la mejora absoluta puede parecer peque√±a, en problemas de churn ‚Äîdonde la clase positiva es minoritaria y estrat√©gica‚Äî incluso incrementos leves en F1-score reflejan un mejor desempe√±o real en la identificaci√≥n de clientes que se dar√°n de baja.

### **2. Estabilidad matem√°tica del modelo**
El modelo:
- no present√≥ warnings de convergencia,
- no requiri√≥ aumentos innecesarios de iteraciones,
- mantuvo coherencia entre accuracy y F1.

Esto lo vuelve m√°s confiable como *artefacto productivo*.

### **3. Robustez frente al ruido**
En modelos lineales como la regressi√≥n log√≠stica:
- la regularizaci√≥n controla la magnitud de los coeficientes,
- coeficientes m√°s peque√±os implican un modelo m√°s estable,
- estabilidad implica mayor resiliencia ante cambios sutiles en la distribuci√≥n del dataset.

En entornos reales (como TelcoVision), la distribuci√≥n de datos cambia mes a mes. Un modelo con C=0.5 responde mejor a estos cambios.

### **4. Adecuaci√≥n al uso en un pipeline productivo**
El modelo final:
- es liviano y r√°pido de ejecutar,
- tiene baja complejidad,
- se versiona de forma simple,
- es reproducible con DVC en cualquier entorno.

Esto lo convierte en un candidato ideal para despliegue en servicios REST, dashboards o pipelines batch.

---

## üöÄ Reflexi√≥n Extendida sobre el Despliegue en Producci√≥n

El despliegue de un modelo de Machine Learning no consiste √∫nicamente en poner en funcionamiento un archivo `model.pkl`. Implica trasladar todo el pipeline ‚Äîdesde la preparaci√≥n de datos hasta el scoring final‚Äî a un entorno capaz de operar con altos niveles de estabilidad, trazabilidad, seguridad y escalabilidad. En organizaciones como TelcoVision, este proceso debe alinearse con pr√°cticas de MLOps, garantizando que el modelo no solo funcione hoy, sino que contin√∫e funcionando de manera confiable a medida que cambian los datos, el negocio y la infraestructura.

A continuaci√≥n se presenta una reflexi√≥n detallada sobre c√≥mo podr√≠a desplegarse este modelo de predicci√≥n de churn en un entorno productivo real, incluyendo alternativas, estrategias y desaf√≠os operativos.

---

### 1. Principios fundamentales para el despliegue

Antes de elegir la arquitectura final, es imprescindible tener presentes los siguientes principios:

- **Reproducibilidad:** La misma versi√≥n del modelo debe producir los mismos resultados en cualquier entorno.
- **Versionado absoluto:** Datos, c√≥digo, modelos y m√©tricas deben contar con versiones expl√≠citas (DVC ya lo resuelve).
- **Escalabilidad:** El servicio debe responder tanto a consultas individuales como a miles de predicciones en procesos batch.
- **Trazabilidad:** Cada predicci√≥n debe ser auditable: qu√© modelo la gener√≥, con qu√© par√°metros y en qu√© momento.
- **Mantenibilidad:** El equipo debe poder actualizar el modelo sin interrumpir servicios cr√≠ticos.
- **Monitoreo activo:** La degradaci√≥n del modelo debe detectarse tempranamente para evitar impactos en el negocio.

El pipeline actual ya cumple varios de estos principios gracias a DVC y GitHub Actions, lo que facilita considerablemente el camino hacia producci√≥n.

---

### 2. Arquitectura de Servicio: API REST con FastAPI

La alternativa m√°s flexible y utilizada en la industria para exponer modelos de ML es el uso de un servicio REST.

#### **C√≥mo funcionar√≠a:**

1. **El servidor carga `models/model.pkl` al iniciar**  
   Esto evita recargar el modelo en cada solicitud, optimizando latencia.

2. **Un endpoint `/predict`** recibe datos de un cliente en formato JSON:

```json
{
  "age": 43,
  "gender": "Male",
  "region": "West",
  "contract_type": "Month-to-Month",
  "tenure_months": 12,
  "monthly_charges": 72.5,
  "total_charges": 850.0,
  "internet_service": "Fiber optic",
  "phone_service": "Yes",
  "multiple_lines": "Yes",
  "payment_method": "Electronic check"
}
```

El servicio:

- aplica el mismo preprocesamiento que se utiliz√≥ en entrenamiento (one-hot encoding),
- genera la probabilidad de churn,
- devuelve una respuesta como:

```json
{
  "probabilidad_churn": 0.72,
  "prediccion": 1
}
```

Ventajas:
- Integraci√≥n inmediata con CRM, sistemas internos o aplicaciones web.
- Respuestas en tiempo real.
- F√°cil balanceo de carga y escalado horizontal.
- Despliegue sencillo en Docker, Kubernetes o servicios cloud.

### 3. Dashboard de An√°lisis para Usuarios de Negocio (Streamlit)
Adem√°s del servicio REST, un dashboard visual aporta un valor decisivo para √°reas como:

- Marketing,
- Fidelizaci√≥n,
- Data Analytics,
- Atenci√≥n al cliente.

**¬øQu√© permitir√≠a un dashboard?**
- Cargar datos de un cliente y obtener su score.
- Manipular variables y observar cambios en el riesgo de churn.
- Mostrar m√©tricas como curva ROC, matriz de confusi√≥n o distribuci√≥n de scores.
- Integrar explicabilidad del modelo con SHAP o LIME, permitiendo conocer qu√© variables influyen m√°s en la predicci√≥n.

Beneficio estrat√©gico:
- Los usuarios sin conocimientos t√©cnicos pueden interactuar con el modelo y comprenderlo.

### 4. Integraci√≥n en Pipelines Batch (Airflow, Control-M, Databricks)
En muchas empresas el scoring de churn se realiza de forma masiva, ejecutando predicciones para miles de clientes en horarios espec√≠ficos del d√≠a o la noche.

**¬øC√≥mo funcionar√≠a?**
1. Airflow o Control-M dispara un job diario.
2. El job ejecuta un script que:
    - carga el dataset diario de clientes,
    - realiza el preprocesamiento,
    -   aplica el modelo versionado,
    - genera un archivo de resultados (CSV, Parquet, API interna).
3. El job guarda el resultado en el Data Lake o lo env√≠a al CRM.
El modelo actual es ideal para esto porque:
    - es ligero,
    - se carga r√°pido,
    - no requiere GPU,
    - funciona bien con procesamiento vectorizado.

### 5. Monitoreo del Modelo en Producci√≥n (ML Monitoring)
Todo modelo se degrada con el tiempo debido a:

- cambios en el comportamiento de clientes,
- nuevos patrones de consumo,
- promociones o cambios en tarifas,
- estacionalidad,
- nuevos m√©todos de pago,
- cambios en el perfil demogr√°fico.

Por eso el monitoreo es esencial.

M√©tricas recomendadas:

- Data drift: comparar la distribuci√≥n de features actuales vs originales.
- Model drift: comparar predicciones con nuevos valores reales.
- F1-score en producci√≥n: si hay etiquetas diferidas (por ejemplo, se sabe al mes siguiente qui√©n churneo).
- Volumen y patrones de predicciones: detectar anomal√≠as.

Herramientas recomendadas:

- Evidently AI
- Prometheus + Grafana
- MLflow Monitoring
- Servicios cloud como Vertex AI Model Monitoring

### 6. Estrategia de Reentrenamiento
Con DVC y GitHub Actions ya configurados, el reentrenamiento puede automatizarse:

1. Un job (manual o programado) actualiza el dataset en data/raw/.
2. Se ejecuta dvc repro.
3. GitHub Actions reconstruye el pipeline.
4. DVC genera una nueva versi√≥n del modelo.
5. El equipo eval√∫a las m√©tricas extendidas.
6. Si el modelo es mejor, se promueve a ‚Äúversi√≥n en producci√≥n‚Äù.

Esta estrategia se llama Continuous Training (CT) y es parte madura de MLOps.

### 7. Versionado y Rollbacks
Gracias a DVC:

- cada dataset tiene un hash,
- cada modelo tiene un hash,
- cada experimento tiene un ID √∫nico.

Esto hace que el rollback sea inmediato:

```php
dvc checkout <versi√≥n-anterior>
```

O incluso desde interfaz web en DagsHub.

Este nivel de trazabilidad es esencial en telecomunicaciones, donde una mala predicci√≥n puede implicar p√©rdidas econ√≥micas o campa√±as err√≥neas.

### 8. Infraestructura de Despliegue Recomendada

Dependiendo de los recursos de TelcoVision, se pueden considerar:

> Opci√≥n A ‚Äì Contenedores (Docker + Kubernetes)

- ideal para microservicios,
- escalado autom√°tico,
- aislamiento limpio.

> Opci√≥n B ‚Äì Serverless (AWS Lambda / Google Cloud Run)

- √≥ptimo si el volumen de predicciones no es constante.
- paga solo por ejecuci√≥n.

> Opci√≥n C ‚Äì On-premise / Virtualizado

- si existen restricciones regulatorias,
- integra con Airflow, Control-M o ETL internos.

#
# Conclusi√≥n

El modelo entrenado, junto con el pipeline reproducible creado con DVC y ejecutado mediante CI/CD en GitHub Actions, est√° completamente preparado para entrar en un proceso de despliegue productivo. El uso de t√©cnicas modernas de MLOps asegura que:

- las predicciones sean confiables,
- el modelo sea trazable,
- los datos est√©n versionados,
- las actualizaciones sean seguras,
- y el rollback sea posible en segundos.

En s√≠ntesis, el trabajo realizado en este proyecto no solo resuelve la predicci√≥n de churn, sino que sienta las bases t√©cnicas para un flujo de MLOps maduro, replicable y escalable en un entorno real de telecomunicaciones.